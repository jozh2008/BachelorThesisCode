<tool name="OTB.TrainVectorClassifier" id="otb_trainvectorclassifier" version="1.0.0">
  <description>Train a classifier based on labeled geometries and a list of features to consider.</description>
  <requirements>
    <requirement version="3.9" type="package">python</requirement>
  </requirements>
  <version_command><![CDATA[interpreter filename.exe --version]]></version_command>
  <command><![CDATA[$__tool_directory__/Code/openapi.py isArrayio_vd True  isArrayio_stats False  isArrayvalid_vd True  output_data_io_out $output_data_io_out  output_data_io_confmatout $output_data_io_confmatout  name OTB.TrainVectorClassifier io_vd $io_vd
io_stats $io_stats
layer $layer
feat '$feat'
valid_vd $valid_vd
valid_layer $valid_layer
cfield '$cfield'
v $v
classifier $classifier
classifier_libsvm_k $classifier_libsvm_k
classifier_libsvm_m $classifier_libsvm_m
classifier_libsvm_c $classifier_libsvm_c
classifier_libsvm_nu $classifier_libsvm_nu
classifier_libsvm_opt $classifier_libsvm_opt
classifier_libsvm_prob $classifier_libsvm_prob
classifier_boost_t $classifier_boost_t
classifier_boost_w $classifier_boost_w
classifier_boost_r $classifier_boost_r
classifier_boost_m $classifier_boost_m
classifier_dt_max $classifier_dt_max
classifier_dt_min $classifier_dt_min
classifier_dt_ra $classifier_dt_ra
classifier_dt_cat $classifier_dt_cat
classifier_dt_f $classifier_dt_f
classifier_dt_r $classifier_dt_r
classifier_dt_t $classifier_dt_t
classifier_ann_t $classifier_ann_t
classifier_ann_sizes '$classifier_ann_sizes'
classifier_ann_f $classifier_ann_f
classifier_ann_a $classifier_ann_a
classifier_ann_b $classifier_ann_b
classifier_ann_bpdw $classifier_ann_bpdw
classifier_ann_bpms $classifier_ann_bpms
classifier_ann_rdw $classifier_ann_rdw
classifier_ann_rdwm $classifier_ann_rdwm
classifier_ann_term $classifier_ann_term
classifier_ann_eps $classifier_ann_eps
classifier_ann_iter $classifier_ann_iter
classifier_rf_max $classifier_rf_max
classifier_rf_min $classifier_rf_min
classifier_rf_ra $classifier_rf_ra
classifier_rf_cat $classifier_rf_cat
classifier_rf_var $classifier_rf_var
classifier_rf_nbtrees $classifier_rf_nbtrees
classifier_rf_acc $classifier_rf_acc
classifier_knn_k $classifier_knn_k
rand $rand
prefer $prefer
response $response
outputType_io_out $OutputSection_io_out.outputType_io_out
transmissionMode_io_out $OutputSection_io_out.transmissionMode_io_out
outputType_io_confmatout $OutputSection_io_confmatout.outputType_io_confmatout
transmissionMode_io_confmatout $OutputSection_io_confmatout.transmissionMode_io_confmatout]]></command>
  <inputs>
    <param name="io_vd" type="data" optional="false" label="Input geometries used for training (note : all geometries from the layer will be used)" help="Input geometries used for training (note : all geometries from the layer will be used) The following data types are allowed in the txt file:  vnd.google-earth.kml+xml, xml, json, zip" format="txt"/>
    <param name="io_stats" type="data" optional="false" label="XML file containing mean and variance of each feature." help="XML file containing mean and variance of each feature. The following data types are allowed in the txt file:  xml" format="txt"/>
    <param name="layer" type="integer" value="0" optional="true" label="Index of the layer to use in the input vector file." help="Index of the layer to use in the input vector file."/>
    <param name="feat" type="text" optional="false" label="List of field names in the input vector data to be used as features for training." help="List of field names in the input vector data to be used as features for training."/>
    <param name="valid_vd" type="data" optional="false" label="Geometries used for validation (must contain the same fields used for training, all geometries from the layer will be used)" help="Geometries used for validation (must contain the same fields used for training, all geometries from the layer will be used) The following data types are allowed in the txt file:  vnd.google-earth.kml+xml, xml, json, zip" format="txt"/>
    <param name="valid_layer" type="integer" value="0" optional="true" label="Index of the layer to use in the validation vector file." help="Index of the layer to use in the validation vector file."/>
    <param name="cfield" type="text" optional="false" label="Field containing the class id for supervision. The values in this field shall be cast into integers. Only geometries with this field available will be taken into account." help="Field containing the class id for supervision. The values in this field shall be cast into integers. Only geometries with this field available will be taken into account."/>
    <param name="v" type="select" optional="false" label="Verbose mode, display the contingency table result." help="Verbose mode, display the contingency table result.">
      <option selected="true" value="false">false</option>
      <option value="true">true</option>
    </param>
    <param name="classifier" type="select" optional="false" label="Choice of the classifier to use for the training." help="Choice of the classifier to use for the training.">
      <option value="ann">ann</option>
      <option value="bayes">bayes</option>
      <option value="boost">boost</option>
      <option value="dt">dt</option>
      <option value="knn">knn</option>
      <option selected="true" value="libsvm">libsvm</option>
      <option value="rf">rf</option>
    </param>
    <param name="classifier_libsvm_k" type="select" optional="false" label="SVM Kernel Type." help="SVM Kernel Type.">
      <option selected="true" value="linear">linear</option>
      <option value="poly">poly</option>
      <option value="rbf">rbf</option>
      <option value="sigmoid">sigmoid</option>
    </param>
    <param name="classifier_libsvm_m" type="select" optional="false" label="Type of SVM formulation." help="Type of SVM formulation.">
      <option selected="true" value="csvc">csvc</option>
      <option value="nusvc">nusvc</option>
      <option value="oneclass">oneclass</option>
    </param>
    <param name="classifier_libsvm_c" type="float" value="1" optional="false" label="SVM models have a cost parameter C (1 by default) to control the trade-off between training errors and forcing rigid margins." help="SVM models have a cost parameter C (1 by default) to control the trade-off between training errors and forcing rigid margins."/>
    <param name="classifier_libsvm_nu" type="float" value="0.5" optional="false" label="Cost parameter Nu, in the range 0..1, the larger the value, the smoother the decision." help="Cost parameter Nu, in the range 0..1, the larger the value, the smoother the decision."/>
    <param name="classifier_libsvm_opt" type="select" optional="false" label="SVM parameters optimization flag." help="SVM parameters optimization flag.">
      <option selected="true" value="false">false</option>
      <option value="true">true</option>
    </param>
    <param name="classifier_libsvm_prob" type="select" optional="false" label="Probability estimation flag." help="Probability estimation flag.">
      <option selected="true" value="false">false</option>
      <option value="true">true</option>
    </param>
    <param name="classifier_boost_t" type="select" optional="false" label="Type of Boosting algorithm." help="Type of Boosting algorithm.">
      <option value="discrete">discrete</option>
      <option value="gentle">gentle</option>
      <option value="logit">logit</option>
      <option selected="true" value="real">real</option>
    </param>
    <param name="classifier_boost_w" type="integer" value="100" optional="false" label="The number of weak classifiers." help="The number of weak classifiers."/>
    <param name="classifier_boost_r" type="float" value="0.95" optional="false" label="A threshold between 0 and 1 used to save computational time. Samples with summary weight &amp;lt;= (1 - weight_trim_rate) do not participate in the next iteration of training. Set this parameter to 0 to turn off this functionality." help="A threshold between 0 and 1 used to save computational time. Samples with summary weight &amp;lt;= (1 - weight_trim_rate) do not participate in the next iteration of training. Set this parameter to 0 to turn off this functionality."/>
    <param name="classifier_boost_m" type="integer" value="1" optional="false" label="Maximum depth of the tree." help="Maximum depth of the tree."/>
    <param name="classifier_dt_max" type="integer" value="10" optional="false" label="The training algorithm attempts to split each node while its depth is smaller than the maximum possible depth of the tree. The actual depth may be smaller if the other termination criteria are met, and/or if the tree is pruned." help="The training algorithm attempts to split each node while its depth is smaller than the maximum possible depth of the tree. The actual depth may be smaller if the other termination criteria are met, and/or if the tree is pruned."/>
    <param name="classifier_dt_min" type="integer" value="10" optional="false" label="If the number of samples in a node is smaller than this parameter, then this node will not be split." help="If the number of samples in a node is smaller than this parameter, then this node will not be split."/>
    <param name="classifier_dt_ra" type="float" value="0.01" optional="false" label="If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split further." help="If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split further."/>
    <param name="classifier_dt_cat" type="integer" value="10" optional="false" label="Cluster possible values of a categorical variable into K &amp;lt;= cat clusters to find a suboptimal split." help="Cluster possible values of a categorical variable into K &amp;lt;= cat clusters to find a suboptimal split."/>
    <param name="classifier_dt_f" type="integer" value="0" optional="false" label="If cv_folds &gt; 1, then it prunes a tree with K-fold cross-validation where K is equal to cv_folds." help="If cv_folds &gt; 1, then it prunes a tree with K-fold cross-validation where K is equal to cv_folds."/>
    <param name="classifier_dt_r" type="select" optional="false" label="If true, then a pruning will be harsher. This will make a tree more compact and more resistant to the training data noise but a bit less accurate." help="If true, then a pruning will be harsher. This will make a tree more compact and more resistant to the training data noise but a bit less accurate.">
      <option selected="true" value="false">false</option>
      <option value="true">true</option>
    </param>
    <param name="classifier_dt_t" type="select" optional="false" label="If true, then pruned branches are physically removed from the tree." help="If true, then pruned branches are physically removed from the tree.">
      <option selected="true" value="false">false</option>
      <option value="true">true</option>
    </param>
    <param name="classifier_ann_t" type="select" optional="false" label="Type of training method for the multilayer perceptron (MLP) neural network." help="Type of training method for the multilayer perceptron (MLP) neural network.">
      <option value="back">back</option>
      <option selected="true" value="reg">reg</option>
    </param>
    <param name="classifier_ann_sizes" type="text" optional="false" label="The number of neurons in each intermediate layer (excluding input and output layers)." help="The number of neurons in each intermediate layer (excluding input and output layers)."/>
    <param name="classifier_ann_f" type="select" optional="false" label="This function determine whether the output of the node is positive or not depending on the output of the transfert function." help="This function determine whether the output of the node is positive or not depending on the output of the transfert function.">
      <option value="gau">gau</option>
      <option value="ident">ident</option>
      <option selected="true" value="sig">sig</option>
    </param>
    <param name="classifier_ann_a" type="float" value="1" optional="false" label="Alpha parameter of the activation function (used only with sigmoid and gaussian functions)." help="Alpha parameter of the activation function (used only with sigmoid and gaussian functions)."/>
    <param name="classifier_ann_b" type="float" value="1" optional="false" label="Beta parameter of the activation function (used only with sigmoid and gaussian functions)." help="Beta parameter of the activation function (used only with sigmoid and gaussian functions)."/>
    <param name="classifier_ann_bpdw" type="float" value="0.1" optional="false" label="Strength of the weight gradient term in the BACKPROP method. The recommended value is about 0.1." help="Strength of the weight gradient term in the BACKPROP method. The recommended value is about 0.1."/>
    <param name="classifier_ann_bpms" type="float" value="0.1" optional="false" label="Strength of the momentum term (the difference between weights on the 2 previous iterations). This parameter provides some inertia to smooth the random fluctuations of the weights. It can vary from 0 (the feature is disabled) to 1 and beyond. The value 0.1 or so is good enough." help="Strength of the momentum term (the difference between weights on the 2 previous iterations). This parameter provides some inertia to smooth the random fluctuations of the weights. It can vary from 0 (the feature is disabled) to 1 and beyond. The value 0.1 or so is good enough."/>
    <param name="classifier_ann_rdw" type="float" value="0.1" optional="false" label="Initial value Delta_0 of update-values Delta_" help="Initial value Delta_0 of update-values Delta_"/>
    <param name="classifier_ann_rdwm" type="float" value="1e-07" optional="false" label="Update-values lower limit Delta_" help="Update-values lower limit Delta_"/>
    <param name="classifier_ann_term" type="select" optional="false" label="Termination criteria." help="Termination criteria.">
      <option selected="true" value="all">all</option>
      <option value="eps">eps</option>
      <option value="iter">iter</option>
    </param>
    <param name="classifier_ann_eps" type="float" value="0.01" optional="false" label="Epsilon value used in the Termination criteria." help="Epsilon value used in the Termination criteria."/>
    <param name="classifier_ann_iter" type="integer" value="1000" optional="false" label="Maximum number of iterations used in the Termination criteria." help="Maximum number of iterations used in the Termination criteria."/>
    <param name="classifier_rf_max" type="integer" value="5" optional="false" label="The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods." help="The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."/>
    <param name="classifier_rf_min" type="integer" value="10" optional="false" label="If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent." help="If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."/>
    <param name="classifier_rf_ra" type="float" value="0" optional="false" label="If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split." help="If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split."/>
    <param name="classifier_rf_cat" type="integer" value="10" optional="false" label="Cluster possible values of a categorical variable into K &amp;lt;= cat clusters to find a suboptimal split." help="Cluster possible values of a categorical variable into K &amp;lt;= cat clusters to find a suboptimal split."/>
    <param name="classifier_rf_var" type="integer" value="0" optional="false" label="The size of the subset of features, randomly selected at each tree node, that are used to find the best split(s). If you set it to 0, then the size will be set to the square root of the total number of features." help="The size of the subset of features, randomly selected at each tree node, that are used to find the best split(s). If you set it to 0, then the size will be set to the square root of the total number of features."/>
    <param name="classifier_rf_nbtrees" type="integer" value="100" optional="false" label="The maximum number of trees in the forest. Typically, the more trees you have, the better the accuracy. However, the improvement in accuracy generally diminishes and reaches an asymptote for a certain number of trees. Also to keep in mind, increasing the number of trees increases the prediction time linearly." help="The maximum number of trees in the forest. Typically, the more trees you have, the better the accuracy. However, the improvement in accuracy generally diminishes and reaches an asymptote for a certain number of trees. Also to keep in mind, increasing the number of trees increases the prediction time linearly."/>
    <param name="classifier_rf_acc" type="float" value="0.01" optional="false" label="Sufficient accuracy (OOB error)." help="Sufficient accuracy (OOB error)."/>
    <param name="classifier_knn_k" type="integer" value="32" optional="false" label="The number of neighbors to use." help="The number of neighbors to use."/>
    <param name="rand" type="integer" optional="true" label="Set specific seed. with integer value." help="Set specific seed. with integer value."/>
    <param name="prefer" type="select" label="Choose the Prefer">
      <option selected="true" value="respond-async;return=representation">respond-async;return=representation</option>
      <option value="return=minimal">return=minimal</option>
      <option value="return=representation">return=representation</option>
    </param>
    <param name="response" type="select" label="Response Type" help="Choose 'raw' for raw data or 'document' for document data.">
      <option selected="true" value="document">document</option>
      <option value="raw">raw</option>
    </param>
    <section name="OutputSection_io_out" title="Select the appropriate transmission mode for the output format" expanded="true">
      <param name="outputType_io_out" type="select" label="Author did not provide help for this parameter... ">
        <option value="text/plain">plain</option>
        <option value="text/xml">xml</option>
      </param>
      <param name="transmissionMode_io_out" type="select" label="Choose the transmission mode">
        <option selected="true" value="reference">reference</option>
        <option value="value">value</option>
      </param>
    </section>
    <section name="OutputSection_io_confmatout" title="Select the appropriate transmission mode for the output format" expanded="true">
      <param name="outputType_io_confmatout" type="select" label="Author did not provide help for this parameter... ">
        <option value="text/csv">csv</option>
      </param>
      <param name="transmissionMode_io_confmatout" type="select" label="Choose the transmission mode">
        <option selected="true" value="reference">reference</option>
        <option value="value">value</option>
      </param>
    </section>
  </inputs>
  <outputs>
    <data name="output_data_io_out" format="xml" label="output_data_io_out" hidden="false">
      <change_format>
        <when input="response" format="txt" value="document"/>
        <when input="outputType_io_out" format="plain" value="text/plain"/>
      </change_format>
    </data>
    <data name="output_data_io_confmatout" format="csv" label="output_data_io_confmatout" hidden="false"/>
  </outputs>
  <tests>
    <test>
      <param name="response" value="document"/>
      <output name="output_data_io_out" ftype="txt" value="output_data_io_out.txt"/>
      <output name="output_data_io_confmatout" ftype="txt" value="output_data_io_confmatout.txt"/>
    </test>
  </tests>
  <help><![CDATA[This application trains a classifier based on labeled geometries and a list of features to consider for classification.This application is based on LibSVM, OpenCV Machine Learning (2.3.1 and later), and Shark ML The output of this application is a text model file, whose format corresponds to the ML model type chosen. There is no image nor vector data output.]]></help>
  <citations>
    <citation type="bibtex">Josh</citation>
  </citations>
</tool>
