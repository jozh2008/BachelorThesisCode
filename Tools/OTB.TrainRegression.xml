<tool name="OTB.TrainRegression" id="otb_trainregression" version="1.0.0">
  <description>Train a classifier from multiple images to perform regression.</description>
  <requirements>
    <requirement version="3.9" type="package">python</requirement>
  </requirements>
  <version_command><![CDATA[interpreter filename.exe --version]]></version_command>
  <command><![CDATA[$__tool_directory__/Code/openapi.py isArrayio.il True  isArrayio.csv False  isArrayio.imstat False  output_data_io.out $output_data_io.out  output_data_io.mse $output_data_io.mse  name OTB.TrainRegression io.il $io.il
io.csv $io.csv
io.imstat $io.imstat
sample.mt $sample.mt
sample.mv $sample.mv
sample.vtr $sample.vtr
classifier $classifier
classifier.libsvm.k $classifier.libsvm.k
classifier.libsvm.m $classifier.libsvm.m
classifier.libsvm.c $classifier.libsvm.c
classifier.libsvm.nu $classifier.libsvm.nu
classifier.libsvm.opt $classifier.libsvm.opt
classifier.libsvm.prob $classifier.libsvm.prob
classifier.libsvm.eps $classifier.libsvm.eps
classifier.dt.max $classifier.dt.max
classifier.dt.min $classifier.dt.min
classifier.dt.ra $classifier.dt.ra
classifier.dt.cat $classifier.dt.cat
classifier.dt.f $classifier.dt.f
classifier.dt.r $classifier.dt.r
classifier.dt.t $classifier.dt.t
classifier.ann.t $classifier.ann.t
classifier.ann.sizes '$classifier.ann.sizes'
classifier.ann.f $classifier.ann.f
classifier.ann.a $classifier.ann.a
classifier.ann.b $classifier.ann.b
classifier.ann.bpdw $classifier.ann.bpdw
classifier.ann.bpms $classifier.ann.bpms
classifier.ann.rdw $classifier.ann.rdw
classifier.ann.rdwm $classifier.ann.rdwm
classifier.ann.term $classifier.ann.term
classifier.ann.eps $classifier.ann.eps
classifier.ann.iter $classifier.ann.iter
classifier.rf.max $classifier.rf.max
classifier.rf.min $classifier.rf.min
classifier.rf.ra $classifier.rf.ra
classifier.rf.cat $classifier.rf.cat
classifier.rf.var $classifier.rf.var
classifier.rf.nbtrees $classifier.rf.nbtrees
classifier.rf.acc $classifier.rf.acc
classifier.knn.k $classifier.knn.k
classifier.knn.rule $classifier.knn.rule
rand $rand
prefer $prefer
response $response
outputType_io.out $OutputSection_io.out.outputType_io.out
transmissionMode_io.out $OutputSection_io.out.transmissionMode_io.out
transmissionMode_io.mse $OutputSection_io.mse.transmissionMode_io.mse]]></command>
  <inputs>
    <param name="io.il" type="data" optional="false" label="A list of input images. First (n-1) bands should contain the predictor. The last band should contain the output value to predict." help="A list of input images. First (n-1) bands should contain the predictor. The last band should contain the output value to predict. The following data types are allowed in the txt file:  tiff, jpeg, png" format="txt"/>
    <param name="io.csv" type="data" optional="false" label="Input CSV file containing the predictors, and the output values in last column. Only used when no input image is given" help="Input CSV file containing the predictors, and the output values in last column. Only used when no input image is given The following data types are allowed in the txt file:  tiff, jpeg, png" format="txt"/>
    <param name="io.imstat" type="data" optional="false" label="Input XML file containing the mean and the standard deviation of the input images." help="Input XML file containing the mean and the standard deviation of the input images. The following data types are allowed in the txt file:  xml" format="txt"/>
    <param name="sample.mt" type="integer" value="1000" optional="false" label="Maximum number of training predictors (default = 1000) (no limit = -1)." help="Maximum number of training predictors (default = 1000) (no limit = -1)."/>
    <param name="sample.mv" type="integer" value="1000" optional="false" label="Maximum number of validation predictors (default = 1000) (no limit = -1)." help="Maximum number of validation predictors (default = 1000) (no limit = -1)."/>
    <param name="sample.vtr" type="float" value="0.5" optional="false" label="Ratio between training and validation samples (0.0 = all training, 1.0 = all validation) (default = 0.5)." help="Ratio between training and validation samples (0.0 = all training, 1.0 = all validation) (default = 0.5)."/>
    <param name="classifier" type="select" optional="false" label="Choice of the classifier to use for the training." help="Choice of the classifier to use for the training.">
      <option value="ann">ann</option>
      <option value="dt">dt</option>
      <option value="knn">knn</option>
      <option selected="true" value="libsvm">libsvm</option>
      <option value="rf">rf</option>
    </param>
    <param name="classifier.libsvm.k" type="select" optional="false" label="SVM Kernel Type." help="SVM Kernel Type.">
      <option selected="true" value="linear">linear</option>
      <option value="poly">poly</option>
      <option value="rbf">rbf</option>
      <option value="sigmoid">sigmoid</option>
    </param>
    <param name="classifier.libsvm.m" type="select" optional="false" label="Type of SVM formulation." help="Type of SVM formulation.">
      <option selected="true" value="epssvr">epssvr</option>
      <option value="nusvr">nusvr</option>
    </param>
    <param name="classifier.libsvm.c" type="float" value="1" optional="false" label="SVM models have a cost parameter C (1 by default) to control the trade-off between training errors and forcing rigid margins." help="SVM models have a cost parameter C (1 by default) to control the trade-off between training errors and forcing rigid margins."/>
    <param name="classifier.libsvm.nu" type="float" value="0.5" optional="false" label="Cost parameter Nu, in the range 0..1, the larger the value, the smoother the decision." help="Cost parameter Nu, in the range 0..1, the larger the value, the smoother the decision."/>
    <param name="classifier.libsvm.opt" type="select" optional="false" label="SVM parameters optimization flag." help="SVM parameters optimization flag.">
      <option selected="true" value="false">false</option>
      <option value="true">true</option>
    </param>
    <param name="classifier.libsvm.prob" type="select" optional="false" label="Probability estimation flag." help="Probability estimation flag.">
      <option selected="true" value="false">false</option>
      <option value="true">true</option>
    </param>
    <param name="classifier.libsvm.eps" type="float" value="0.001" optional="false" label="The distance between feature vectors from the training set and the fitting hyper-plane must be less than Epsilon. For outliersthe penalty mutliplier is set by C." help="The distance between feature vectors from the training set and the fitting hyper-plane must be less than Epsilon. For outliersthe penalty mutliplier is set by C."/>
    <param name="classifier.dt.max" type="integer" value="10" optional="false" label="The training algorithm attempts to split each node while its depth is smaller than the maximum possible depth of the tree. The actual depth may be smaller if the other termination criteria are met, and/or if the tree is pruned." help="The training algorithm attempts to split each node while its depth is smaller than the maximum possible depth of the tree. The actual depth may be smaller if the other termination criteria are met, and/or if the tree is pruned."/>
    <param name="classifier.dt.min" type="integer" value="10" optional="false" label="If the number of samples in a node is smaller than this parameter, then this node will not be split." help="If the number of samples in a node is smaller than this parameter, then this node will not be split."/>
    <param name="classifier.dt.ra" type="float" value="0.01" optional="false" label="If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split further." help="If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split further."/>
    <param name="classifier.dt.cat" type="integer" value="10" optional="false" label="Cluster possible values of a categorical variable into K &amp;lt;= cat clusters to find a suboptimal split." help="Cluster possible values of a categorical variable into K &amp;lt;= cat clusters to find a suboptimal split."/>
    <param name="classifier.dt.f" type="integer" value="0" optional="false" label="If cv_folds &gt; 1, then it prunes a tree with K-fold cross-validation where K is equal to cv_folds." help="If cv_folds &gt; 1, then it prunes a tree with K-fold cross-validation where K is equal to cv_folds."/>
    <param name="classifier.dt.r" type="select" optional="false" label="If true, then a pruning will be harsher. This will make a tree more compact and more resistant to the training data noise but a bit less accurate." help="If true, then a pruning will be harsher. This will make a tree more compact and more resistant to the training data noise but a bit less accurate.">
      <option selected="true" value="false">false</option>
      <option value="true">true</option>
    </param>
    <param name="classifier.dt.t" type="select" optional="false" label="If true, then pruned branches are physically removed from the tree." help="If true, then pruned branches are physically removed from the tree.">
      <option selected="true" value="false">false</option>
      <option value="true">true</option>
    </param>
    <param name="classifier.ann.t" type="select" optional="false" label="Type of training method for the multilayer perceptron (MLP) neural network." help="Type of training method for the multilayer perceptron (MLP) neural network.">
      <option value="back">back</option>
      <option selected="true" value="reg">reg</option>
    </param>
    <param name="classifier.ann.sizes" type="text" optional="false" label="The number of neurons in each intermediate layer (excluding input and output layers)." help="The number of neurons in each intermediate layer (excluding input and output layers)."/>
    <param name="classifier.ann.f" type="select" optional="false" label="This function determine whether the output of the node is positive or not depending on the output of the transfert function." help="This function determine whether the output of the node is positive or not depending on the output of the transfert function.">
      <option value="gau">gau</option>
      <option value="ident">ident</option>
      <option selected="true" value="sig">sig</option>
    </param>
    <param name="classifier.ann.a" type="float" value="1" optional="false" label="Alpha parameter of the activation function (used only with sigmoid and gaussian functions)." help="Alpha parameter of the activation function (used only with sigmoid and gaussian functions)."/>
    <param name="classifier.ann.b" type="float" value="1" optional="false" label="Beta parameter of the activation function (used only with sigmoid and gaussian functions)." help="Beta parameter of the activation function (used only with sigmoid and gaussian functions)."/>
    <param name="classifier.ann.bpdw" type="float" value="0.1" optional="false" label="Strength of the weight gradient term in the BACKPROP method. The recommended value is about 0.1." help="Strength of the weight gradient term in the BACKPROP method. The recommended value is about 0.1."/>
    <param name="classifier.ann.bpms" type="float" value="0.1" optional="false" label="Strength of the momentum term (the difference between weights on the 2 previous iterations). This parameter provides some inertia to smooth the random fluctuations of the weights. It can vary from 0 (the feature is disabled) to 1 and beyond. The value 0.1 or so is good enough." help="Strength of the momentum term (the difference between weights on the 2 previous iterations). This parameter provides some inertia to smooth the random fluctuations of the weights. It can vary from 0 (the feature is disabled) to 1 and beyond. The value 0.1 or so is good enough."/>
    <param name="classifier.ann.rdw" type="float" value="0.1" optional="false" label="Initial value Delta_0 of update-values Delta_" help="Initial value Delta_0 of update-values Delta_"/>
    <param name="classifier.ann.rdwm" type="float" value="1e-07" optional="false" label="Update-values lower limit Delta_" help="Update-values lower limit Delta_"/>
    <param name="classifier.ann.term" type="select" optional="false" label="Termination criteria." help="Termination criteria.">
      <option selected="true" value="all">all</option>
      <option value="eps">eps</option>
      <option value="iter">iter</option>
    </param>
    <param name="classifier.ann.eps" type="float" value="0.01" optional="false" label="Epsilon value used in the Termination criteria." help="Epsilon value used in the Termination criteria."/>
    <param name="classifier.ann.iter" type="integer" value="1000" optional="false" label="Maximum number of iterations used in the Termination criteria." help="Maximum number of iterations used in the Termination criteria."/>
    <param name="classifier.rf.max" type="integer" value="5" optional="false" label="The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods." help="The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."/>
    <param name="classifier.rf.min" type="integer" value="10" optional="false" label="If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent." help="If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."/>
    <param name="classifier.rf.ra" type="float" value="0" optional="false" label="If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split." help="If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split."/>
    <param name="classifier.rf.cat" type="integer" value="10" optional="false" label="Cluster possible values of a categorical variable into K &amp;lt;= cat clusters to find a suboptimal split." help="Cluster possible values of a categorical variable into K &amp;lt;= cat clusters to find a suboptimal split."/>
    <param name="classifier.rf.var" type="integer" value="0" optional="false" label="The size of the subset of features, randomly selected at each tree node, that are used to find the best split(s). If you set it to 0, then the size will be set to the square root of the total number of features." help="The size of the subset of features, randomly selected at each tree node, that are used to find the best split(s). If you set it to 0, then the size will be set to the square root of the total number of features."/>
    <param name="classifier.rf.nbtrees" type="integer" value="100" optional="false" label="The maximum number of trees in the forest. Typically, the more trees you have, the better the accuracy. However, the improvement in accuracy generally diminishes and reaches an asymptote for a certain number of trees. Also to keep in mind, increasing the number of trees increases the prediction time linearly." help="The maximum number of trees in the forest. Typically, the more trees you have, the better the accuracy. However, the improvement in accuracy generally diminishes and reaches an asymptote for a certain number of trees. Also to keep in mind, increasing the number of trees increases the prediction time linearly."/>
    <param name="classifier.rf.acc" type="float" value="0.01" optional="false" label="Sufficient accuracy (OOB error)." help="Sufficient accuracy (OOB error)."/>
    <param name="classifier.knn.k" type="integer" value="32" optional="false" label="The number of neighbors to use." help="The number of neighbors to use."/>
    <param name="classifier.knn.rule" type="select" optional="false" label="Decision rule for regression output" help="Decision rule for regression output">
      <option selected="true" value="mean">mean</option>
      <option value="median">median</option>
    </param>
    <param name="rand" type="integer" optional="true" label="Set specific seed. with integer value." help="Set specific seed. with integer value."/>
    <param name="prefer" type="select" label="Choose the Prefer">
      <option selected="true" value="respond-async;return=representation">respond-async;return=representation</option>
      <option value="return=minimal">return=minimal</option>
      <option value="return=representation">return=representation</option>
    </param>
    <param name="response" type="select" label="Response Type" help="Choose 'raw' for raw data or 'document' for document data.">
      <option selected="true" value="document">document</option>
      <option value="raw">raw</option>
    </param>
    <section name="OutputSection_io.out" title="Select the appropriate transmission mode for the output format" expanded="true">
      <param name="outputType_io.out" type="select" label="Author did not provide help for this parameter... ">
        <option value="text/plain">plain</option>
        <option value="text/xml">xml</option>
      </param>
      <param name="transmissionMode_io.out" type="select" label="Choose the transmission mode">
        <option selected="true" value="reference">reference</option>
        <option value="value">value</option>
      </param>
    </section>
    <section name="OutputSection_io.mse" title="Select the appropriate transmission mode for the output format" expanded="true">
      <param name="transmissionMode_io.mse" type="select" label="Choose the transmission mode">
        <option selected="true" value="reference">reference</option>
        <option value="value">value</option>
      </param>
    </section>
  </inputs>
  <outputs>
    <data name="output_data_io.out" format="xml" hidden="false">
      <change_format>
        <when input="response" format="txt" value="document"/>
        <when input="outputType_io.out" format="plain" value="text/plain"/>
      </change_format>
    </data>
    <data name="output_data_io.mse" format="txt" hidden="false"/>
  </outputs>
  <tests>
    <test>
      <output name="output_data" ftype="txt"/>
      <param name="response" value="document"/>
    </test>
  </tests>
  <help><![CDATA[This application trains a classifier from multiple input images or a csv file, in order to perform regression. Predictors are composed of pixel values in each band optionally centered and reduced using an XML statistics file produced by the ComputeImagesStatistics application. The output value for each predictor is assumed to be the last band (or the last column for CSV files). Training and validation predictor lists are built such that their size is inferior to maximum bounds given by the user, and the proportion corresponds to the balance parameter. Several classifier parameters can be set depending on the chosen classifier. In the validation process, the mean square error is computed between the ground truth and the estimated model. This application is based on LibSVM and on OpenCV Machine Learning classifiers, and is compatible with OpenCV 2.3.1 and later.]]></help>
  <citations>
    <citation type="bibtex">Josh</citation>
  </citations>
</tool>
